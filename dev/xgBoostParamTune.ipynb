{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MoA Kaggle- Drug Discovery\n",
    "\n",
    "#### MultiLabel Classification problem\n",
    "\n",
    "[Kaggle Link](https://www.kaggle.com/c/lish-moa/data)\n",
    "\n",
    "In cuurent approaches for Drug discovery, Scientists seek to identify a protein target associated with a disease and develop a molecule that can modulate that protein target. As a shorthand to describe the biological activity of a given molecule, scientists assign a label referred to as mechanism-of-action or MoA for short.\n",
    "\n",
    "Effects of a drug on the protien target\n",
    "\n",
    "**Metric** is average logloss for all classes\n",
    "\n",
    "#### Xgboost 1 variable paramTuning and Feature Importance\n",
    "\n",
    "Out of 206 target variables, cyclooxygenase_inhibitor has highest LogLoss 0f 0.092 with Deep neuarl net, \n",
    "Goal is to reduce this with xgboost.\n",
    "\n",
    "See work on predWork notebook for details about individual losses for variables\n",
    "\n",
    "Why not use scikit-learn grid searches\n",
    "* Added flexibility\n",
    "* Ease of analyzing param effects\n",
    "* We can add a additional validation set, which is not part of the Cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "* Build on 50K-100k sample, if dataset is larger\n",
    "* Param tune with cv,\n",
    "* Pick least overfitted and best performing models\n",
    "* var reduction based on impotances and voting\n",
    "* regularization\n",
    "* drop vars 1 at a time and coorrelated vars \n",
    "* Final grid search - on reduced var list\n",
    "* pick the least overfitted model with accepatble loss reduction as final model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Fns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridParamTune(dtrain,gridParams,EvalMetric,params,Drop=1,verbose=1):\n",
    "    '''\n",
    "    Xgboost Param tuning\n",
    "    Author: Taran\n",
    "    \n",
    "    Given a params dictionary this function implements Grid and random search\n",
    "    The cv object can be replaced for any other model\n",
    "    \n",
    "    Args - dTrain matrix,\n",
    "            gridParams A parameters dictinary with candidate search space\n",
    "            Drop Rate - for  Random search [0,1]\n",
    "            verbose 0 0r 1 \n",
    "            params  ---not to be tuned parameters\n",
    "            EvalMetric  -- takes 1 eval metric\n",
    "    Output\n",
    "    Returns a df with results for each params\n",
    "    Additional dependency itertools\n",
    "    \n",
    "    '''\n",
    "    import itertools\n",
    "    #paramers passed\n",
    "    paramNames = list(gridParams.keys())\n",
    "    \n",
    "    results = []\n",
    "    ### iterate over all combinations\n",
    "    for row in itertools.product(*gridParams.values()):\n",
    "        ### random search threshold\n",
    "        if np.random.random(1)[0] < Drop:\n",
    "            continue \n",
    "        \n",
    "        # insert values into param dict\n",
    "        for i in range(len(row)):\n",
    "            params[paramNames[i]] = row[i]\n",
    "            \n",
    "        # train model for given params    \n",
    "        cvN = xgb.cv(\n",
    "                    params,\n",
    "                    dtrain,\n",
    "                    num_boost_round=1000,\n",
    "                    seed=42,\n",
    "                    nfold=5,\n",
    "                    metrics={EvalMetric},\n",
    "                    early_stopping_rounds=25\n",
    "                )\n",
    "        #get results \n",
    "        bestRound= cvN[f'test-{EvalMetric}-mean'].argmin()\n",
    "        trainMetric = cvN[f'train-{EvalMetric}-mean'][bestRound]\n",
    "        testMetric =cvN[f'test-{EvalMetric}-mean'][bestRound]\n",
    "        overfit = ((cvN[f'test-{EvalMetric}-mean'][bestRound]/cvN[f'train-{EvalMetric}-mean'][bestRound]) -1)*100\n",
    "        \n",
    "        #unlist\n",
    "        tempResults=[list(params.values())[1:],bestRound,trainMetric,testMetric,overfit]      \n",
    "\n",
    "        results.append(list(itertools.chain.from_iterable(i if isinstance(i, list) else [i] for i in tempResults)))\n",
    "         \n",
    "    colNames=[paramNames,'bestRound',f'train-{EvalMetric}',f'test-{EvalMetric}','overfit']              \n",
    "    df = pd.DataFrame(results,columns=list(itertools.chain.from_iterable(i if isinstance(i, list) else [i] for i in colNames)))\n",
    "                  \n",
    "    return df\n",
    "\n",
    "def overFitRelations(paramName,paramResults=paramResults):\n",
    "    '''\n",
    "    Arg - paramName\n",
    "    returns a plot and a df showing over fit relation\n",
    "    '''\n",
    "    df = paramResults.groupby([paramName])['overfit'].mean()\n",
    "    print(df.plot.bar(title=f'{paramName} vs overfitting'))\n",
    "    return df\n",
    "\n",
    "def getLogLoss(y,yhat):\n",
    "    '''\n",
    "    logloss\n",
    "    '''\n",
    "    assert len(y)==len(yhat)\n",
    "    eps= 1e-12\n",
    "    \n",
    "    yhat= np.clip(yhat,eps,1-eps)\n",
    "    return -1*np.mean(y*np.log(yhat) + (1-y)*np.log(1-yhat))\n",
    "\n",
    "\n",
    "def PreProcessX(df):\n",
    "    '''\n",
    "    Preprocessing for independent  vars\n",
    "    encode categoricals\n",
    "    \n",
    "    returns processed df,\n",
    "    '''\n",
    "    df['cp_dose'] = (df['cp_dose'] == 'D1').astype(int)\n",
    "    df['cp_type'] = (df['cp_type'] == 'trt_cp').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def flattenList(myList):\n",
    "    '''\n",
    "    Flattens a list and returns it\n",
    "    '''\n",
    "    import itertools\n",
    "    return list(itertools.chain.from_iterable(i if isinstance(i, list) else [i] for i in myList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAll = pd.read_csv('../Data/train_features.csv')\n",
    "yAll = pd.read_csv('../Data/train_targets_scored.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAll = PreProcessX(xAll)\n",
    "\n",
    "trainIds= xAll['sig_id'].sample(frac=0.8,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain (19051, 876) yTrain (19051, 207) xValid (4763, 876) yValid (4763, 207)\n"
     ]
    }
   ],
   "source": [
    "xTrain = xAll[xAll['sig_id'].isin(trainIds)]\n",
    "yTrain = yAll[yAll['sig_id'].isin(trainIds)]\n",
    "xValid = xAll[~xAll['sig_id'].isin(trainIds)]\n",
    "yValid = yAll[~yAll['sig_id'].isin(trainIds)]\n",
    "print(f'xTrain {xTrain.shape} yTrain {yTrain.shape} xValid {xValid.shape} yValid {yValid.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idList=['sig_id']\n",
    "xTrain=xTrain.drop(idList,axis=1)\n",
    "xValid=xValid.drop(idList,axis=1)\n",
    "yTrain=yTrain.drop(idList,axis=1)\n",
    "yValid=yValid.drop(idList,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(xTrain, label=yTrain['cyclooxygenase_inhibitor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not tuning gamma and max leaves # to be tuned based on overfit\n",
    "\n",
    "NumRows =xTrain.shape[0]*0.8 ### 0.8 is due to 5 fold cv\n",
    "gridParams = {\n",
    "   \n",
    "    'max_depth' : [4,6,8],\n",
    "    'eta' : [0.01,0.05,0.1],\n",
    "    'colsample_bytree' : [0.2,0.5,1],\n",
    "    'min_child_weight' : [1,int(NumRows*0.005)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not to be tuned params\n",
    "params = {\n",
    "    'objective':'binary:logistic'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20h 57min 12s, sys: 54 s, total: 20h 58min 6s\n",
      "Wall time: 1h 46min 24s\n"
     ]
    }
   ],
   "source": [
    "%time paramResults=GridParamTune(dtrain=dtrain,gridParams=gridParams,EvalMetric='logloss',params=params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection criteria\n",
    "\n",
    "Sort by logloss,\n",
    "\n",
    "Obs\n",
    "All models got trained fully bestRound < Numrounds\n",
    "\n",
    "Since the goal was to regularize the model later,\n",
    "we can pick 5 with lower log loss and 1 least overfitted from those \n",
    "\n",
    "In trhe second stage we will pick the model with the lowest logloss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>eta</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>bestRound</th>\n",
       "      <th>train-logloss</th>\n",
       "      <th>test-logloss</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>676</td>\n",
       "      <td>0.059015</td>\n",
       "      <td>0.087648</td>\n",
       "      <td>48.517844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0.065939</td>\n",
       "      <td>0.087667</td>\n",
       "      <td>32.950961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>727</td>\n",
       "      <td>0.057525</td>\n",
       "      <td>0.087668</td>\n",
       "      <td>52.398419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>617</td>\n",
       "      <td>0.061563</td>\n",
       "      <td>0.087897</td>\n",
       "      <td>42.775554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0.061070</td>\n",
       "      <td>0.087942</td>\n",
       "      <td>44.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0.056511</td>\n",
       "      <td>0.087970</td>\n",
       "      <td>55.669162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0.060099</td>\n",
       "      <td>0.087984</td>\n",
       "      <td>46.397290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>0.056675</td>\n",
       "      <td>0.087984</td>\n",
       "      <td>55.244148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>568</td>\n",
       "      <td>0.042952</td>\n",
       "      <td>0.087992</td>\n",
       "      <td>104.860309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>0.061466</td>\n",
       "      <td>0.088024</td>\n",
       "      <td>43.208884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0.048817</td>\n",
       "      <td>0.088038</td>\n",
       "      <td>80.343242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>536</td>\n",
       "      <td>0.044331</td>\n",
       "      <td>0.088076</td>\n",
       "      <td>98.680821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>597</td>\n",
       "      <td>0.041690</td>\n",
       "      <td>0.088119</td>\n",
       "      <td>111.368728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0.046736</td>\n",
       "      <td>0.088304</td>\n",
       "      <td>88.943808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>14.103527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>0.033285</td>\n",
       "      <td>0.088422</td>\n",
       "      <td>165.648002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0.076891</td>\n",
       "      <td>0.088477</td>\n",
       "      <td>15.068044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>744</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>0.088501</td>\n",
       "      <td>14.694760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.048708</td>\n",
       "      <td>0.088514</td>\n",
       "      <td>81.723741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>724</td>\n",
       "      <td>0.077734</td>\n",
       "      <td>0.088543</td>\n",
       "      <td>13.905112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0.078616</td>\n",
       "      <td>0.088555</td>\n",
       "      <td>12.643292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0.035213</td>\n",
       "      <td>0.088558</td>\n",
       "      <td>151.488354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>163</td>\n",
       "      <td>0.078004</td>\n",
       "      <td>0.088581</td>\n",
       "      <td>13.559852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>135</td>\n",
       "      <td>0.077944</td>\n",
       "      <td>0.088588</td>\n",
       "      <td>13.655118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>171</td>\n",
       "      <td>0.076115</td>\n",
       "      <td>0.088590</td>\n",
       "      <td>16.390242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>728</td>\n",
       "      <td>0.079187</td>\n",
       "      <td>0.088611</td>\n",
       "      <td>11.902014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>467</td>\n",
       "      <td>0.033967</td>\n",
       "      <td>0.088663</td>\n",
       "      <td>161.023805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>750</td>\n",
       "      <td>0.077795</td>\n",
       "      <td>0.088719</td>\n",
       "      <td>14.041483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0.049430</td>\n",
       "      <td>0.088723</td>\n",
       "      <td>79.494068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>65</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.088739</td>\n",
       "      <td>12.033158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>137</td>\n",
       "      <td>0.078610</td>\n",
       "      <td>0.088740</td>\n",
       "      <td>12.885892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>180</td>\n",
       "      <td>0.076482</td>\n",
       "      <td>0.088749</td>\n",
       "      <td>16.039591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>159</td>\n",
       "      <td>0.078523</td>\n",
       "      <td>0.088761</td>\n",
       "      <td>13.037930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>152</td>\n",
       "      <td>0.079164</td>\n",
       "      <td>0.088765</td>\n",
       "      <td>12.127674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.044422</td>\n",
       "      <td>0.088786</td>\n",
       "      <td>99.868084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>760</td>\n",
       "      <td>0.077956</td>\n",
       "      <td>0.088788</td>\n",
       "      <td>13.894469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>751</td>\n",
       "      <td>0.079331</td>\n",
       "      <td>0.088793</td>\n",
       "      <td>11.927211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "      <td>0.079368</td>\n",
       "      <td>0.088794</td>\n",
       "      <td>11.876887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>163</td>\n",
       "      <td>0.078464</td>\n",
       "      <td>0.088801</td>\n",
       "      <td>13.174993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>0.078810</td>\n",
       "      <td>0.088811</td>\n",
       "      <td>12.690807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>114</td>\n",
       "      <td>0.074892</td>\n",
       "      <td>0.088821</td>\n",
       "      <td>18.598515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>182</td>\n",
       "      <td>0.078505</td>\n",
       "      <td>0.088846</td>\n",
       "      <td>13.172121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>0.080109</td>\n",
       "      <td>0.088934</td>\n",
       "      <td>11.015936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>763</td>\n",
       "      <td>0.078966</td>\n",
       "      <td>0.088939</td>\n",
       "      <td>12.629454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0.035209</td>\n",
       "      <td>0.088939</td>\n",
       "      <td>152.603596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>0.079191</td>\n",
       "      <td>0.088952</td>\n",
       "      <td>12.326684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>763</td>\n",
       "      <td>0.078761</td>\n",
       "      <td>0.088956</td>\n",
       "      <td>12.944543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>773</td>\n",
       "      <td>0.079891</td>\n",
       "      <td>0.088966</td>\n",
       "      <td>11.360285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.089003</td>\n",
       "      <td>160.393444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>0.089161</td>\n",
       "      <td>78.822387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.033942</td>\n",
       "      <td>0.089273</td>\n",
       "      <td>163.015361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0.033759</td>\n",
       "      <td>0.089462</td>\n",
       "      <td>164.999378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.036144</td>\n",
       "      <td>0.089551</td>\n",
       "      <td>147.761178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.036494</td>\n",
       "      <td>0.089613</td>\n",
       "      <td>145.553838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth   eta  colsample_bytree  min_child_weight  bestRound  \\\n",
       "2           4  0.01               0.5                 1        676   \n",
       "14          4  0.10               0.5                 1         56   \n",
       "0           4  0.01               0.2                 1        727   \n",
       "4           4  0.01               1.0                 1        617   \n",
       "10          4  0.05               1.0                 1        123   \n",
       "12          4  0.10               0.2                 1         72   \n",
       "16          4  0.10               1.0                 1         62   \n",
       "6           4  0.05               0.2                 1        146   \n",
       "20          6  0.01               0.5                 1        568   \n",
       "8           4  0.05               0.5                 1        126   \n",
       "28          6  0.05               1.0                 1         98   \n",
       "22          6  0.01               1.0                 1        536   \n",
       "18          6  0.01               0.2                 1        597   \n",
       "26          6  0.05               0.5                 1        105   \n",
       "35          6  0.10               1.0                76         73   \n",
       "38          8  0.01               0.5                 1        487   \n",
       "53          8  0.10               1.0                76         76   \n",
       "41          8  0.01               1.0                76        744   \n",
       "34          6  0.10               1.0                 1         48   \n",
       "23          6  0.01               1.0                76        724   \n",
       "17          4  0.10               1.0                76         76   \n",
       "46          8  0.05               1.0                 1         90   \n",
       "11          4  0.05               1.0                76        163   \n",
       "47          8  0.05               1.0                76        135   \n",
       "29          6  0.05               1.0                76        171   \n",
       "5           4  0.01               1.0                76        728   \n",
       "40          8  0.01               1.0                 1        467   \n",
       "39          8  0.01               0.5                76        750   \n",
       "24          6  0.05               0.2                 1        104   \n",
       "33          6  0.10               0.5                76         65   \n",
       "45          8  0.05               0.5                76        137   \n",
       "27          6  0.05               0.5                76        180   \n",
       "43          8  0.05               0.2                76        159   \n",
       "9           4  0.05               0.5                76        152   \n",
       "32          6  0.10               0.5                 1         54   \n",
       "21          6  0.01               0.5                76        760   \n",
       "3           4  0.01               0.5                76        751   \n",
       "51          8  0.10               0.5                76         62   \n",
       "25          6  0.05               0.2                76        163   \n",
       "15          4  0.10               0.5                76         79   \n",
       "49          8  0.10               0.2                76        114   \n",
       "7           4  0.05               0.2                76        182   \n",
       "13          4  0.10               0.2                76         74   \n",
       "19          6  0.01               0.2                76        763   \n",
       "44          8  0.05               0.5                 1         93   \n",
       "31          6  0.10               0.2                76         74   \n",
       "37          8  0.01               0.2                76        763   \n",
       "1           4  0.01               0.2                76        773   \n",
       "36          8  0.01               0.2                 1        496   \n",
       "30          6  0.10               0.2                 1         51   \n",
       "52          8  0.10               1.0                 1         45   \n",
       "42          8  0.05               0.2                 1         99   \n",
       "48          8  0.10               0.2                 1         48   \n",
       "50          8  0.10               0.5                 1         45   \n",
       "\n",
       "    train-logloss  test-logloss     overfit  \n",
       "2        0.059015      0.087648   48.517844  \n",
       "14       0.065939      0.087667   32.950961  \n",
       "0        0.057525      0.087668   52.398419  \n",
       "4        0.061563      0.087897   42.775554  \n",
       "10       0.061070      0.087942   44.002109  \n",
       "12       0.056511      0.087970   55.669162  \n",
       "16       0.060099      0.087984   46.397290  \n",
       "6        0.056675      0.087984   55.244148  \n",
       "20       0.042952      0.087992  104.860309  \n",
       "8        0.061466      0.088024   43.208884  \n",
       "28       0.048817      0.088038   80.343242  \n",
       "22       0.044331      0.088076   98.680821  \n",
       "18       0.041690      0.088119  111.368728  \n",
       "26       0.046736      0.088304   88.943808  \n",
       "35       0.077471      0.088398   14.103527  \n",
       "38       0.033285      0.088422  165.648002  \n",
       "53       0.076891      0.088477   15.068044  \n",
       "41       0.077162      0.088501   14.694760  \n",
       "34       0.048708      0.088514   81.723741  \n",
       "23       0.077734      0.088543   13.905112  \n",
       "17       0.078616      0.088555   12.643292  \n",
       "46       0.035213      0.088558  151.488354  \n",
       "11       0.078004      0.088581   13.559852  \n",
       "47       0.077944      0.088588   13.655118  \n",
       "29       0.076115      0.088590   16.390242  \n",
       "5        0.079187      0.088611   11.902014  \n",
       "40       0.033967      0.088663  161.023805  \n",
       "39       0.077795      0.088719   14.041483  \n",
       "24       0.049430      0.088723   79.494068  \n",
       "33       0.079208      0.088739   12.033158  \n",
       "45       0.078610      0.088740   12.885892  \n",
       "27       0.076482      0.088749   16.039591  \n",
       "43       0.078523      0.088761   13.037930  \n",
       "9        0.079164      0.088765   12.127674  \n",
       "32       0.044422      0.088786   99.868084  \n",
       "21       0.077956      0.088788   13.894469  \n",
       "3        0.079331      0.088793   11.927211  \n",
       "51       0.079368      0.088794   11.876887  \n",
       "25       0.078464      0.088801   13.174993  \n",
       "15       0.078810      0.088811   12.690807  \n",
       "49       0.074892      0.088821   18.598515  \n",
       "7        0.078505      0.088846   13.172121  \n",
       "13       0.080109      0.088934   11.015936  \n",
       "19       0.078966      0.088939   12.629454  \n",
       "44       0.035209      0.088939  152.603596  \n",
       "31       0.079191      0.088952   12.326684  \n",
       "37       0.078761      0.088956   12.944543  \n",
       "1        0.079891      0.088966   11.360285  \n",
       "36       0.034180      0.089003  160.393444  \n",
       "30       0.049860      0.089161   78.822387  \n",
       "52       0.033942      0.089273  163.015361  \n",
       "42       0.033759      0.089462  164.999378  \n",
       "48       0.036144      0.089551  147.761178  \n",
       "50       0.036494      0.089613  145.553838  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramResults.sort_values(['test-logloss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overFitRelations('min_child_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overFitRelations('max_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEdCAYAAAAVczy7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWbklEQVR4nO3debhkdX3n8fcHGkRBROSmgzTaTmDkwTGiTw/BkZkYBXcFxyg6Ehsl0+MkbmM0EicLQcxgJq7jJIa4NYuAcQGiE5e0oHFBaWRRIEZUkJ2LAuIu8p0/6nehKG73rbv3r/v9ep7z3LOfb51T9bmnfnVOVaoKSVJ/tlvuAiRJc2OAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygDfCiRZnaSSrFjuWqYkOTbJKfNcx7lJfnehatLdkqxM8rkktyd5c5LXJ3n3LNfxriR/slg1amZbzAteWkhJCti3qq5Y7lq2UOuAm4Fda+RmkCSrge8AO1TVHW3cUcDvVtXBU/NV1UuXrFpNyzNwbZO2pHcrSykD2wEPBS4bDW/1xQDfwiTZO8lHkkwm+V6Sd7bx2yX54yRXJbkpyUlJHrCJdRyV5Nvt7fF3krywjf+1JJ9p6705yalJdhta7sokr01ySZIfJXlPe6v9j21d/5TkgW3eqWabdUmuS3J9ktds5nEdlOSLSW5NcnGSx4+5S34tyVeS/CDJWUl2b+v7eJKXj2zjkiTPTvK5NuriJD9MckSSxye5JsnrktwAvK/t02OSfKvtkw9OrX82Nbd1fmhk3NuTvGNzx2Oa9dwnydva/ryu9d+nTbs8yTOG5l3RniOPmanW1hT1xiRfAH4MnASsBf6w7Z9DRpq8pvbfrW36Y4F3AY9tw7e29b4/yfGtf2r//kF7fl6f5MVDNTwoyT+043h+kuOTfH66/aBZqCq7LaQDtgcuBt4K7AzsBBzcpr0EuAL4N8AuwEeAk9u01UAxaBLbGfgB8PA2bU/gEa1/H+BQ4D7ABIMX6tuGtn8lcB6wEtgLuAn4KvDoVstngD8b2eZpbZuPBCaBQ9r0Y4FTWv9ewPeApzE4aTi0DU/MsD/OBa4F/l3bxoeH1vk84MtD8z6qrXPHNlzAPkPTHw/cAbypPf77Aq9sj3dVG/e3wGmzrZnB2eyPgfsPHcfrgYM2dzymWc9xrZ5facfni8Ab2rQ/BU4dmvfpwOXj1Nr243eBR7TnyA7A+4Hjh9Y3fLymju2KoelHAZ8fqfeudQzt3+Pa+p/W9skD2/TTW3c/YH/g6tH12c0hM5a7ALuhgwGPZRCCK6aZtgH4vaHhhwO/aC/Iu15wLTBuBZ4D3HeG7R0OXDg0fCXwwqHhDwN/MzT8cuDM1j+1zf2Gpv8l8J7WPxwIr6P9sxma95PA2hnqOxc4YWh4f+DnDAJyJ+AWBu3cAH8F/PXQvNMF+M+BnYbGXQ48cWh4z6F9Oquagc8DL2r9hwLfav2zOR7fAp42NPxk4MrWvw9wO3C/Nnwq8Kfj7N+2H48bmf5+Fj7AfzKyzE0M/olt3/brw4emHT+6PrvZdzahbFn2Bq6q9sHRiAcDVw0NX8UgaFYOz1RVPwKOAF4KXN+aGvaDu648OD3JtUl+AJwC7DGynRuH+n8yzfAuI/NfPVLTg6ep/aHAc9vb+1vbW/CDGQTmTEbXvwOwR1X9FDgDODKDNt0XACfPsK7JttxwXR8dquly4JcM9ulsa/5AqwHgv7ThzR6PaUx3jB/c1nNFq++ZSe4HPGtqG2PWOrwfF8v3Rp67P2bwfJlg8FwdrmEp6tnqGeBblquBh2T6D9iuY/BCnfIQBm9Zbxydsao+WVWHMngB/wvwd23SXzA4s3pkVe0KHAlknjXvPVLTddPMczWDM8Tdhrqdq+qEOaz/FwyungBYD7wQeCLw46r60gzrGv3A7mrgqSN17VRV186h5r8HHp9kFfBs7g7XzR2PUdMd4+H9eRqDfxKHMfgAcuoKm3Fqnc2HldPNO58POycZPFdXDY3bexPzahYM8C3LVxi0nZ6QZOckOyV5XJt2GvA/kjwsyS4MwviM0bP1dpZ9WJKdgZ8BPwTubJPv34ZvS7IX8NoFqPlPktwvySOAFzM4Kx51CoMzxycn2b49rqmwm8mRSfZvZ53HAR+qql8CtMC+E3gz9z77vpHB5wWb8y7gjUkeCpBkIslhc6m5qiYZNFW8D/hOVV3e1rm54zHqNOCPWx17MGj3Hr6W/nTgScB/Z+gfxGxrHcNkq3F4/90IrEqy42xX1o7XR4Bj23NlP+BFc6xNQwzwLUh7oj+TQXvnd4FrGLz9Bngvg5D6HINrdH/KoE161HbAqxmcuX0f+E0GL3iAPwceA9wGfJzBi2q+Psvgw9UNwF9V1aemeVxXMzhrfD2DcLiawT+PcZ5/JzNoa72BQbv3K0amn8TgA9TRm4aOBda3JoXnbWLdbwfOBj6V5HYGHyD+xjxq/gBwCPcM180dj1HHAxuBS4CvMfgA+fipiVV1PfAl4D8w9I9ynvv3Xqrqx8AbgS+0/XcQgw+wLwVuSHLzZlcwvZcBD2BwHE9m8M/qZ3OpT3dLlZeBavYyzc0ey1THi4B1NXSDibZ8Sd4E/GpVrV3uWnrmGbi61ZpVfg84cblr0eYl2S/Jr2fgQOBo4KPLXVfvDHAtq3ZjyHTdf5xhuSczaC64kXs2WWjLdH8GTXY/YtD882bgrGWtaCtgE4okdcozcEnqlAEuSZ1a0m9k22OPPWr16tVLuUlJ6t4FF1xwc1VNjI5f0gBfvXo1GzduXMpNSlL3klw13XibUCSpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdWtIbeZba6mM+vtwlLKorT3j6cpcgaRl5Bi5JnTLAJalTBrgkdcoAl6RObdUfYqpffgAtzcwAl7Tg/Ae8NGxCkaROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVNjfR94kiuB24FfAndU1ZokuwNnAKuBK4HnVdUti1OmJGnUbM7Af6uqDqiqNW34GGBDVe0LbGjDkqQlMp8mlMOA9a1/PXD4vKuRJI1t3AAv4FNJLkiyro1bWVXXt/4bgJXTLZhkXZKNSTZOTk7Os1xJ0pRxfxPz4Kq6NsmvAJ9O8i/DE6uqktR0C1bVicCJAGvWrJl2HknS7I11Bl5V17a/NwEfBQ4EbkyyJ0D7e9NiFSlJurcZAzzJzknuP9UPPAn4OnA2sLbNthY4a7GKlCTd2zhNKCuBjyaZmv8DVfWJJOcDH0xyNHAV8LzFK1OSNGrGAK+qbwOPmmb894AnLkZRkqSZeSemJHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktSpsQM8yfZJLkzysTb8sCRfTnJFkjOS7Lh4ZUqSRs3mDPyVwOVDw28C3lpV+wC3AEcvZGGSpM0bK8CTrAKeDry7DQd4AvChNst64PBFqE+StAnjnoG/DfhD4M42/CDg1qq6ow1fA+w13YJJ1iXZmGTj5OTkfGqVJA2ZMcCTPAO4qaoumMsGqurEqlpTVWsmJibmsgpJ0jRWjDHP44BnJXkasBOwK/B2YLckK9pZ+Crg2sUrU5I0asYz8Kr6o6paVVWrgecDn6mqFwLnAL/dZlsLnLVoVUqS7mU+14G/Dnh1kisYtIm/Z2FKkiSNY5wmlLtU1bnAua3/28CBC1+SJGkc3okpSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHVqxgBPslOSryS5OMmlSf68jX9Yki8nuSLJGUl2XPxyJUlTxjkD/xnwhKp6FHAA8JQkBwFvAt5aVfsAtwBHL1qVkqR7mTHAa+CHbXCH1hXwBOBDbfx64PDFKFCSNL2x2sCTbJ/kIuAm4NPAt4Bbq+qONss1wF6LUqEkaVpjBXhV/bKqDgBWAQcC+427gSTrkmxMsnFycnJuVUqS7mVWV6FU1a3AOcBjgd2SrGiTVgHXbmKZE6tqTVWtmZiYmE+tkqQh41yFMpFkt9Z/X+BQ4HIGQf7bbba1wFmLVKMkaRorZp6FPYH1SbZnEPgfrKqPJbkMOD3J8cCFwHsWsU5J0ogZA7yqLgEePc34bzNoD5ckLQPvxJSkThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnZgzwJHsnOSfJZUkuTfLKNn73JJ9O8s3294GLX64kaco4Z+B3AH9QVfsDBwG/n2R/4BhgQ1XtC2xow5KkJTJjgFfV9VX11dZ/O3A5sBdwGLC+zbYeOHyRapQkTWNWbeBJVgOPBr4MrKyq69ukG4CVm1hmXZKNSTZOTk7Op1ZJ0pCxAzzJLsCHgVdV1Q+Gp1VVATXdclV1YlWtqao1ExMT8ypWknS3sQI8yQ4MwvvUqvpIG31jkj3b9D2BmxanREnSdMa5CiXAe4DLq+otQ5POBta2/rXAWQtfniRpU1aMMc/jgN8Bvpbkojbu9cAJwAeTHA1cBTxvUSqUJE1rxgCvqs8D2cTkJy5sOZKkcXknpiR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUqRkDPMl7k9yU5OtD43ZP8ukk32x/H7i4ZUqSRo1zBv5+4Ckj444BNlTVvsCGNixJWkIzBnhVfQ74/sjow4D1rX89cPjCliVJmslc28BXVtX1rf8GYOUC1SNJGtO8P8SsqgJqU9OTrEuyMcnGycnJ+W5OktTMNcBvTLInQPt706ZmrKoTq2pNVa2ZmJiY4+YkSaPmGuBnA2tb/1rgrIUpR5I0rnEuIzwN+BLw8CTXJDkaOAE4NMk3gUPasCRpCa2YaYaqesEmJj1xgWuRJM2Cd2JKUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpU/MK8CRPSfKNJFckOWahipIkzWzOAZ5ke+D/Ak8F9gdekGT/hSpMkrR58zkDPxC4oqq+XVU/B04HDluYsiRJM1kxj2X3Aq4eGr4G+I3RmZKsA9a1wR8m+cY8trml2wO4eak2ljct1Za2CR67vm3tx++h042cT4CPpapOBE5c7O1sCZJsrKo1y12HZs9j17dt9fjNpwnlWmDvoeFVbZwkaQnMJ8DPB/ZN8rAkOwLPB85emLIkSTOZcxNKVd2R5GXAJ4HtgfdW1aULVlmftommoq2Ux65v2+TxS1Utdw2SpDnwTkxJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4HOQZO8kpyf55ySvT7LD0LQzl7E0jSHJS4b6VyXZkOTWJF9M8m+XszaNL8nKJI9p3crlrmc5GOBz817gXODlwJ7AZ5M8qE2b9jsLtEV52VD/W4AzgN2B/w38zbJUpLElOSDJeQxeg3/Zus8mOS/JY5a1uCXmdeBzkOSiqjpgaPhI4I+AZwF/X1Xb1JOoN0m+OnWMpjmWF1bVo5etOM0oyUXAf6uqL4+MPwj426p61LIUtgwW/custlI7JNmpqn4KUFWnJLmBwV2pOy9vaRrDqiTvAAJMJNmhqn7Rpu2wmeW0Zdh5NLwBquq8JNvU688An5t3M/jq3M9Ojaiqf0ryXAZv57Rle+1Q/0ZgF+CWJL+K3+fTg39M8nHgJO7+Suu9gRcBn1i2qpaBTSiSupPkqQx+QGavNupa4Oyq+n/LV9XSM8AXWJJnVNXHlrsOzY3HTz3xKpSF9++XuwDNi8evY+0XwLYZtoHPUZL9mP4t3J8tX1Ual8dvq5XlLmApeQY+B0lex+BHnAN8pXUBTktyzHLWppl5/LZqP1/uApaSbeBzkORfgUcMXXo2NX5H4NKq2nd5KtM4PH5bryTfraqHLHcdS8UmlLm5E3gwcNXI+D3bNG3ZPH4dS3LJpiYB29Qt9Qb43LwK2JDkm9x9HepDgH24523a2jK9Co9fz1YCTwZuGRkf4ItLX87yMcDnoKo+0b706EDu+SHY+VX1y+WrTOPw+HXvY8AuVXXR6IQk5y55NcvINnBJ6pRXoUhSpwxwSeqUAa4tQpJjk7xmGbZ7VJJ3zmG5WdXbvsP6abPdjrQ5Bri0NA4Apg3wJF5MoDkxwLWokrwoySVJLk5ycpLVST7Txm1Icq+bLpK8IsllbZ7T27gDk3wpyYXtp88e3sYfleTMJJ9OcmWSlyV5dZvvvCS7t/nOTfL2JBcl+XqSA6fZ7kSSDyc5v3WPm+HhParV9M0k/7Wt46Qkhw+t89QkhwHHAUe07R/RzuBPTvIF4ORNbTvJzknem+Qr7TEdNqcDoa1TVdnZLUoHPAL4V2CPNrw78A/A2jb8EuDM1n8s8JrWfx1wn9a/W/u7K7Ci9R8CfLj1HwVcAdwfmABuA17apr0VeFXrPxf4u9b/n4CvDy3/ztb/AeDg1v8Q4PLNPLZjgYuB+wJ7MLie/MHAbw49pgcA32Fwue5d2xla/gLgvpvbNvAXwJFT+6Ltz52X+9jabRmdb920mJ7A4Cfmbgaoqu8neSzwn9v0k5n+BzAuAU5tPxB9Zhv3AGB9kn2B4p6/nHNOVd0O3J7kNgb/JAC+Bvz60HyntTo+l2TXJLuNbPcQYP/kru9D2jXJLlX1w008vrOq6ifAT5KcAxxYVWcm+eskE8BzGPyjuWNoncPObstvctvAk4BnDbW370QL+E3UpG2IAa4t0dMZnCU/E/ifSR4JvIFBUD87yWoGZ9RTfjbUf+fQ8J3c8zk+etPD6PB2wEHVfipvDJta30nAkcDzgRdvZvkfzbTtDBL9OVX1jTFr0jbENnAtps8Az03yIIDWHv1FBsEG8ELgn4cXSLIdsHdVnQO8jsGZ9y7t77VttqPmWM8RbRsHA7dV1W0j0z8FvHyolgNmWN9hSXZqj+/xwPlt/PsZ3K5PVV3Wxt3OoJlnUza17U8CL29BThJ/cFl3McC1aKrqUuCNwGeTXAy8hUFIvbh9IdHvAK8cWWx74JQkXwMuBN5RVbcyaGr5X0kuZO7vHH/aln8XcPQ0018BrGkfnl4GvHSG9V0CnAOcB7yhqq4DqKobGTRxvG9o3nMYNJFclOSIWWz7DQyaiy5JcmkblgBvpdc2on1HxmuqauMSbOt+DNrfHzPNWb60YDwDlxZQkkMYnH3/H8Nbi80zcGkzkryYezfzfKGqfn856pGGGeCS1CmbUCSpUwa4JHXKAJekThngktQpA1ySOvX/AUPMTBKNCIycAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overFitRelations('colsample_bytree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepth = list(paramResults.sort_values(['test-logloss'])[:2]['max_depth'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, [4, 4]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDepth.append(list(paramResults.sort_values(['overfit'])[:2]['max_depth'].values))\n",
    "maxDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenList(myList):\n",
    "    '''\n",
    "    Flattens a list and returns it\n",
    "    '''\n",
    "    import itertools\n",
    "    return list(itertools.chain.from_iterable(i if isinstance(i, list) else [i] for i in myList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(flattenList(maxDepth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParams(paramName,paramResults,n=1):\n",
    "    '''\n",
    "    selects unique params from df returned by paramResults df\n",
    "    n number of params sets selected\n",
    "    '''\n",
    "    temp = list(paramResults.sort_values(['test-logloss'])[:2][paramName].values)\n",
    "    temp.append(list(paramResults.sort_values(['overfit'])[:2][paramName].values))\n",
    "    return set(flattenList(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getParams('max_depth',paramResults=paramResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 76}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getParams(paramName='min_child_weight',paramResults=paramResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2, 0.5}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getParams(paramName='colsample_bytree',paramResults=paramResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.01, 0.1}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getParams(paramName='eta',paramResults=paramResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>eta</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>bestRound</th>\n",
       "      <th>train-logloss</th>\n",
       "      <th>test-logloss</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>0.080109</td>\n",
       "      <td>0.088934</td>\n",
       "      <td>11.015936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>676</td>\n",
       "      <td>0.059015</td>\n",
       "      <td>0.087648</td>\n",
       "      <td>48.517844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth   eta  colsample_bytree  min_child_weight  bestRound  \\\n",
       "13          4  0.10               0.2                76         74   \n",
       "2           4  0.01               0.5                 1        676   \n",
       "\n",
       "    train-logloss  test-logloss    overfit  \n",
       "13       0.080109      0.088934  11.015936  \n",
       "2        0.059015      0.087648  48.517844  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramResults.sort_values(['overfit'])[:1].append(\n",
    "paramResults.sort_values(['test-logloss'])[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances from selected models\n",
    "\n",
    "Features are correlated so we might see lot of variation in important features returned by different models.\n",
    "\n",
    "As we increase number of trees we might see the number of features returned also increase,\n",
    "\n",
    "We will take average of feature importances returned( normalized gains) and select vraibles with cummulative importance <0.80,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Feature importances\n",
    "# least over fitted\n",
    "NumRows =xTrain.shape[0]\n",
    "\n",
    "\n",
    "params1 = {\n",
    "    'max_depth' : 4,\n",
    "    'eta' : 0.1,\n",
    "    'colsample_bytree' : 0.2,\n",
    "    'min_child_weight' : int(NumRows*0.005),\n",
    "    'objective':'multi:softprob',\n",
    "    'num_class':2\n",
    "}\n",
    "\n",
    "\n",
    "params2 = {\n",
    "    'max_depth' : 4,\n",
    "    'eta' : 0.01,\n",
    "    'colsample_bytree' : 0.5,\n",
    "    'min_child_weight' : 1,\n",
    "    'objective':'multi:softprob',\n",
    "    'num_class':2\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.3 s, sys: 23.9 ms, total: 47.4 s\n",
      "Wall time: 4.04 s\n"
     ]
    }
   ],
   "source": [
    "%time mod1 = xgb.train(params1,dtrain, num_boost_round=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 27s, sys: 200 ms, total: 21min 27s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%time mod2 = xgb.train(params2,dtrain, num_boost_round=676)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.086167923948375\n",
      "0.08501716379982831\n"
     ]
    }
   ],
   "source": [
    "## Results on valid test\n",
    "print(getLogLoss(yValid['cyclooxygenase_inhibitor'],mod1.predict(xgb.DMatrix(xValid))[:,1]))\n",
    "print(getLogLoss(yValid['cyclooxygenase_inhibitor'],mod2.predict(xgb.DMatrix(xValid))[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp1 =pd.DataFrame(mod1.get_score(importance_type='gain').items(),\n",
    "             columns=['variable','Gain']).sort_values(['Gain'],ascending=False).reset_index(drop=True)\n",
    "imp2 =pd.DataFrame(mod2.get_score(importance_type='gain').items(),\n",
    "             columns=['variable','Gain']).sort_values(['Gain'],ascending=False).reset_index(drop=True)\n",
    "imp = pd.merge(imp2,imp1,how='left',on=['variable'],suffixes=['_1', '_2'])\n",
    "\n",
    "imp= imp.fillna(0)\n",
    "\n",
    "#Normalizing\n",
    "imp['Gain_1'] = imp['Gain_1']/imp['Gain_1'].sum()\n",
    "imp['Gain_2'] = imp['Gain_2']/imp['Gain_2'].sum()\n",
    "\n",
    "#average\n",
    "imp['AvgGain'] = (imp['Gain_1']+imp['Gain_2'])*100/2\n",
    "imp = imp.sort_values('AvgGain',ascending=False).reset_index(drop=True)\n",
    "\n",
    "imp['CummProp'] = imp['AvgGain'].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>Gain_1</th>\n",
       "      <th>Gain_2</th>\n",
       "      <th>AvgGain</th>\n",
       "      <th>CummProp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g-526</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.008485</td>\n",
       "      <td>0.546406</td>\n",
       "      <td>0.546406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g-158</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.502161</td>\n",
       "      <td>1.048568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g-459</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>0.477393</td>\n",
       "      <td>1.525961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g-536</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>0.475750</td>\n",
       "      <td>2.001711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g-515</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.458484</td>\n",
       "      <td>2.460195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>g-64</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081389</td>\n",
       "      <td>79.605129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>g-419</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081089</td>\n",
       "      <td>79.686218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>g-378</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080916</td>\n",
       "      <td>79.767135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>g-390</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080824</td>\n",
       "      <td>79.847959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>g-367</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.080124</td>\n",
       "      <td>79.928082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    variable    Gain_1    Gain_2   AvgGain   CummProp\n",
       "0      g-526  0.002443  0.008485  0.546406   0.546406\n",
       "1      g-158  0.001187  0.008856  0.502161   1.048568\n",
       "2      g-459  0.001501  0.008046  0.477393   1.525961\n",
       "3      g-536  0.002037  0.007478  0.475750   2.001711\n",
       "4      g-515  0.001520  0.007649  0.458484   2.460195\n",
       "..       ...       ...       ...       ...        ...\n",
       "385     g-64  0.001628  0.000000  0.081389  79.605129\n",
       "386    g-419  0.001622  0.000000  0.081089  79.686218\n",
       "387    g-378  0.001618  0.000000  0.080916  79.767135\n",
       "388    g-390  0.001616  0.000000  0.080824  79.847959\n",
       "389    g-367  0.000181  0.001421  0.080124  79.928082\n",
       "\n",
       "[390 rows x 5 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp[imp['CummProp'] <= 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramResults.to_csv('../dumps/1stGrid_cyclooxygenase_inhibitor.csv')\n",
    "imp.to_csv('../dumps/VarImp_cyclooxygenase_inhibitor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19051, 390)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain[imp[imp['CummProp'] <= 80]['variable']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd grid serach on the selected varibles\n",
    "\n",
    "Will be based on the results from 1st with added regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "## selected variables\n",
    "dtrain = xgb.DMatrix(xTrain[imp[imp['CummProp'] <= 80]['variable']], label=yTrain['cyclooxygenase_inhibitor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NumRows =xTrain.shape[0]*0.8 ### 0.8 is due to 5 fold cv\n",
    "gridParams = {\n",
    "   \n",
    "    'max_depth' : [3,4,5]\n",
    "    ,'eta' : [0.01,0.1]\n",
    "    ,'colsample_bytree' : [0.3,0.6]\n",
    "    ,'gamma': [0,0.1,0.5]# 0 is default\n",
    "    ,'min_child_weight' : [1,int(NumRows*0.0025),int(NumRows*0.005)]# 1 is default\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20h 38min 50s, sys: 27.1 s, total: 20h 39min 17s\n",
      "Wall time: 1h 44min 13s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective':'binary:logistic'\n",
    "}\n",
    "%time paramResults2=GridParamTune(dtrain=dtrain,gridParams=gridParams,EvalMetric='logloss',params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>eta</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>bestRound</th>\n",
       "      <th>train-logloss</th>\n",
       "      <th>test-logloss</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>978</td>\n",
       "      <td>0.045069</td>\n",
       "      <td>0.086095</td>\n",
       "      <td>91.026728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>993</td>\n",
       "      <td>0.059650</td>\n",
       "      <td>0.086119</td>\n",
       "      <td>44.373661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>948</td>\n",
       "      <td>0.046388</td>\n",
       "      <td>0.086121</td>\n",
       "      <td>85.655218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>0.054534</td>\n",
       "      <td>0.086127</td>\n",
       "      <td>57.934558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>789</td>\n",
       "      <td>0.040434</td>\n",
       "      <td>0.086135</td>\n",
       "      <td>113.026166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>763</td>\n",
       "      <td>0.042060</td>\n",
       "      <td>0.086221</td>\n",
       "      <td>104.998145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>993</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.086224</td>\n",
       "      <td>44.633134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>917</td>\n",
       "      <td>0.046019</td>\n",
       "      <td>0.086256</td>\n",
       "      <td>87.434755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>0.045286</td>\n",
       "      <td>0.086256</td>\n",
       "      <td>90.468662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>0.048781</td>\n",
       "      <td>0.086265</td>\n",
       "      <td>76.841393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>996</td>\n",
       "      <td>0.060807</td>\n",
       "      <td>0.086283</td>\n",
       "      <td>41.896163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>998</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.086312</td>\n",
       "      <td>42.024202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>997</td>\n",
       "      <td>0.060812</td>\n",
       "      <td>0.086319</td>\n",
       "      <td>41.943366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0.060389</td>\n",
       "      <td>0.086330</td>\n",
       "      <td>42.956025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>874</td>\n",
       "      <td>0.048108</td>\n",
       "      <td>0.086332</td>\n",
       "      <td>79.453900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>0.039134</td>\n",
       "      <td>0.086345</td>\n",
       "      <td>120.639958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>686</td>\n",
       "      <td>0.045238</td>\n",
       "      <td>0.086352</td>\n",
       "      <td>90.883811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>797</td>\n",
       "      <td>0.039974</td>\n",
       "      <td>0.086356</td>\n",
       "      <td>116.027257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.059402</td>\n",
       "      <td>0.086359</td>\n",
       "      <td>45.380933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>713</td>\n",
       "      <td>0.043326</td>\n",
       "      <td>0.086416</td>\n",
       "      <td>99.456213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth   eta  colsample_bytree  gamma  min_child_weight  bestRound  \\\n",
       "42          4  0.01               0.3    0.5                 1        978   \n",
       "12          3  0.01               0.6    0.1                 1        993   \n",
       "36          4  0.01               0.3    0.0                 1        948   \n",
       "24          3  0.10               0.3    0.5                 1        116   \n",
       "75          5  0.01               0.3    0.1                 1        789   \n",
       "78          5  0.01               0.3    0.5                 1        763   \n",
       "9           3  0.01               0.6    0.0                 1        993   \n",
       "45          4  0.01               0.6    0.0                 1        917   \n",
       "33          3  0.10               0.6    0.5                 1        143   \n",
       "39          4  0.01               0.3    0.1                 1        899   \n",
       "6           3  0.01               0.3    0.5                 1        996   \n",
       "3           3  0.01               0.3    0.1                 1        998   \n",
       "0           3  0.01               0.3    0.0                 1        997   \n",
       "18          3  0.10               0.3    0.0                 1         98   \n",
       "51          4  0.01               0.6    0.5                 1        874   \n",
       "57          4  0.10               0.3    0.1                 1        107   \n",
       "81          5  0.01               0.6    0.0                 1        686   \n",
       "72          5  0.01               0.3    0.0                 1        797   \n",
       "15          3  0.01               0.6    0.5                 1        999   \n",
       "84          5  0.01               0.6    0.1                 1        713   \n",
       "\n",
       "    train-logloss  test-logloss     overfit  \n",
       "42       0.045069      0.086095   91.026728  \n",
       "12       0.059650      0.086119   44.373661  \n",
       "36       0.046388      0.086121   85.655218  \n",
       "24       0.054534      0.086127   57.934558  \n",
       "75       0.040434      0.086135  113.026166  \n",
       "78       0.042060      0.086221  104.998145  \n",
       "9        0.059616      0.086224   44.633134  \n",
       "45       0.046019      0.086256   87.434755  \n",
       "33       0.045286      0.086256   90.468662  \n",
       "39       0.048781      0.086265   76.841393  \n",
       "6        0.060807      0.086283   41.896163  \n",
       "3        0.060773      0.086312   42.024202  \n",
       "0        0.060812      0.086319   41.943366  \n",
       "18       0.060389      0.086330   42.956025  \n",
       "51       0.048108      0.086332   79.453900  \n",
       "57       0.039134      0.086345  120.639958  \n",
       "81       0.045238      0.086352   90.883811  \n",
       "72       0.039974      0.086356  116.027257  \n",
       "15       0.059402      0.086359   45.380933  \n",
       "84       0.043326      0.086416   99.456213  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramResults2.sort_values(['test-logloss']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have improved on logloss\n",
    "\n",
    "best round greater than >975 means model has the potential to train more\n",
    "\n",
    "We can pick least over fitted from top 5 with lowest loss or take 1 model from least overfitted ones with less drop in performance \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overFitRelations(paramName,paramResults):\n",
    "    '''\n",
    "    Arg - paramName\n",
    "    returns a plot and a df showing over fit relation\n",
    "    '''\n",
    "    df = paramResults.groupby([paramName])['overfit'].mean()\n",
    "    print(df.plot.bar(title=f'{paramName} vs overfitting'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>eta</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>bestRound</th>\n",
       "      <th>train-logloss</th>\n",
       "      <th>test-logloss</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>828</td>\n",
       "      <td>0.080302</td>\n",
       "      <td>0.088480</td>\n",
       "      <td>10.184330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>825</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>0.088451</td>\n",
       "      <td>10.765370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>843</td>\n",
       "      <td>0.079668</td>\n",
       "      <td>0.088456</td>\n",
       "      <td>11.031029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>849</td>\n",
       "      <td>0.079632</td>\n",
       "      <td>0.088439</td>\n",
       "      <td>11.060406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>789</td>\n",
       "      <td>0.079599</td>\n",
       "      <td>0.088442</td>\n",
       "      <td>11.109185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>0.079445</td>\n",
       "      <td>0.088307</td>\n",
       "      <td>11.154327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>796</td>\n",
       "      <td>0.079510</td>\n",
       "      <td>0.088411</td>\n",
       "      <td>11.194818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>86</td>\n",
       "      <td>0.079372</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>11.448564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>989</td>\n",
       "      <td>0.078673</td>\n",
       "      <td>0.088411</td>\n",
       "      <td>12.378134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>827</td>\n",
       "      <td>0.078501</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>12.440319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth   eta  colsample_bytree  gamma  min_child_weight  bestRound  \\\n",
       "2           3  0.01               0.3    0.0                76        828   \n",
       "14          3  0.01               0.6    0.1                76        825   \n",
       "11          3  0.01               0.6    0.0                76        843   \n",
       "17          3  0.01               0.6    0.5                76        849   \n",
       "38          4  0.01               0.3    0.0                76        789   \n",
       "65          4  0.10               0.6    0.0                76         74   \n",
       "41          4  0.01               0.3    0.1                76        796   \n",
       "29          3  0.10               0.6    0.0                76         86   \n",
       "8           3  0.01               0.3    0.5                76        989   \n",
       "50          4  0.01               0.6    0.1                76        827   \n",
       "\n",
       "    train-logloss  test-logloss    overfit  \n",
       "2        0.080302      0.088480  10.184330  \n",
       "14       0.079854      0.088451  10.765370  \n",
       "11       0.079668      0.088456  11.031029  \n",
       "17       0.079632      0.088439  11.060406  \n",
       "38       0.079599      0.088442  11.109185  \n",
       "65       0.079445      0.088307  11.154327  \n",
       "41       0.079510      0.088411  11.194818  \n",
       "29       0.079372      0.088459  11.448564  \n",
       "8        0.078673      0.088411  12.378134  \n",
       "50       0.078501      0.088267  12.440319  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramResults2.sort_values(['overfit']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "min_child_weight\n",
       "1     78.034963\n",
       "38    31.890048\n",
       "76    15.448526\n",
       "Name: overfit, dtype: float64"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overFitRelations('min_child_weight',paramResults=paramResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "max_depth\n",
       "3    32.269339\n",
       "4    44.243258\n",
       "5    48.860940\n",
       "Name: overfit, dtype: float64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overFitRelations('max_depth',paramResults=paramResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gamma\n",
       "0.0    41.256922\n",
       "0.1    42.926565\n",
       "0.5    41.190050\n",
       "Name: overfit, dtype: float64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overFitRelations('gamma',paramResults=paramResults2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma is harder to tune,\n",
    "\n",
    "For this dataset We can control overfitting by tweaking min_child_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0860946"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramResults2['test-logloss'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>eta</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>bestRound</th>\n",
       "      <th>train-logloss</th>\n",
       "      <th>test-logloss</th>\n",
       "      <th>overfit</th>\n",
       "      <th>perfDrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>828</td>\n",
       "      <td>0.080302</td>\n",
       "      <td>0.088480</td>\n",
       "      <td>10.184330</td>\n",
       "      <td>1.027707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>825</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>0.088451</td>\n",
       "      <td>10.765370</td>\n",
       "      <td>1.027368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>843</td>\n",
       "      <td>0.079668</td>\n",
       "      <td>0.088456</td>\n",
       "      <td>11.031029</td>\n",
       "      <td>1.027430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>849</td>\n",
       "      <td>0.079632</td>\n",
       "      <td>0.088439</td>\n",
       "      <td>11.060406</td>\n",
       "      <td>1.027235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>789</td>\n",
       "      <td>0.079599</td>\n",
       "      <td>0.088442</td>\n",
       "      <td>11.109185</td>\n",
       "      <td>1.027263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>0.079445</td>\n",
       "      <td>0.088307</td>\n",
       "      <td>11.154327</td>\n",
       "      <td>1.025697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>796</td>\n",
       "      <td>0.079510</td>\n",
       "      <td>0.088411</td>\n",
       "      <td>11.194818</td>\n",
       "      <td>1.026905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>86</td>\n",
       "      <td>0.079372</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>11.448564</td>\n",
       "      <td>1.027467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>989</td>\n",
       "      <td>0.078673</td>\n",
       "      <td>0.088411</td>\n",
       "      <td>12.378134</td>\n",
       "      <td>1.026903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>827</td>\n",
       "      <td>0.078501</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>12.440319</td>\n",
       "      <td>1.025233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>995</td>\n",
       "      <td>0.078592</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>12.503054</td>\n",
       "      <td>1.026991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>830</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.088336</td>\n",
       "      <td>12.587370</td>\n",
       "      <td>1.026030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>839</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>0.088307</td>\n",
       "      <td>12.647432</td>\n",
       "      <td>1.025695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>777</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.088311</td>\n",
       "      <td>12.746883</td>\n",
       "      <td>1.025741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>856</td>\n",
       "      <td>0.078175</td>\n",
       "      <td>0.088359</td>\n",
       "      <td>13.027728</td>\n",
       "      <td>1.026304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>89</td>\n",
       "      <td>0.077765</td>\n",
       "      <td>0.088291</td>\n",
       "      <td>13.535583</td>\n",
       "      <td>1.025516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>999</td>\n",
       "      <td>0.077507</td>\n",
       "      <td>0.088307</td>\n",
       "      <td>13.934153</td>\n",
       "      <td>1.025702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>996</td>\n",
       "      <td>0.076851</td>\n",
       "      <td>0.088274</td>\n",
       "      <td>14.864425</td>\n",
       "      <td>1.025314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>89</td>\n",
       "      <td>0.076794</td>\n",
       "      <td>0.088245</td>\n",
       "      <td>14.911022</td>\n",
       "      <td>1.024977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>108</td>\n",
       "      <td>0.076733</td>\n",
       "      <td>0.088260</td>\n",
       "      <td>15.023341</td>\n",
       "      <td>1.025156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth   eta  colsample_bytree  gamma  min_child_weight  bestRound  \\\n",
       "2            3  0.01               0.3    0.0                76        828   \n",
       "14           3  0.01               0.6    0.1                76        825   \n",
       "11           3  0.01               0.6    0.0                76        843   \n",
       "17           3  0.01               0.6    0.5                76        849   \n",
       "38           4  0.01               0.3    0.0                76        789   \n",
       "65           4  0.10               0.6    0.0                76         74   \n",
       "41           4  0.01               0.3    0.1                76        796   \n",
       "29           3  0.10               0.6    0.0                76         86   \n",
       "8            3  0.01               0.3    0.5                76        989   \n",
       "50           4  0.01               0.6    0.1                76        827   \n",
       "5            3  0.01               0.3    0.1                76        995   \n",
       "77           5  0.01               0.3    0.1                76        830   \n",
       "53           4  0.01               0.6    0.5                76        839   \n",
       "89           5  0.01               0.6    0.5                76        777   \n",
       "74           5  0.01               0.3    0.0                76        856   \n",
       "68           4  0.10               0.6    0.1                76         89   \n",
       "44           4  0.01               0.3    0.5                76        999   \n",
       "80           5  0.01               0.3    0.5                76        996   \n",
       "104          5  0.10               0.6    0.1                76         89   \n",
       "56           4  0.10               0.3    0.0                76        108   \n",
       "\n",
       "     train-logloss  test-logloss    overfit  perfDrop  \n",
       "2         0.080302      0.088480  10.184330  1.027707  \n",
       "14        0.079854      0.088451  10.765370  1.027368  \n",
       "11        0.079668      0.088456  11.031029  1.027430  \n",
       "17        0.079632      0.088439  11.060406  1.027235  \n",
       "38        0.079599      0.088442  11.109185  1.027263  \n",
       "65        0.079445      0.088307  11.154327  1.025697  \n",
       "41        0.079510      0.088411  11.194818  1.026905  \n",
       "29        0.079372      0.088459  11.448564  1.027467  \n",
       "8         0.078673      0.088411  12.378134  1.026903  \n",
       "50        0.078501      0.088267  12.440319  1.025233  \n",
       "5         0.078592      0.088418  12.503054  1.026991  \n",
       "77        0.078460      0.088336  12.587370  1.026030  \n",
       "53        0.078392      0.088307  12.647432  1.025695  \n",
       "89        0.078327      0.088311  12.746883  1.025741  \n",
       "74        0.078175      0.088359  13.027728  1.026304  \n",
       "68        0.077765      0.088291  13.535583  1.025516  \n",
       "44        0.077507      0.088307  13.934153  1.025702  \n",
       "80        0.076851      0.088274  14.864425  1.025314  \n",
       "104       0.076794      0.088245  14.911022  1.024977  \n",
       "56        0.076733      0.088260  15.023341  1.025156  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramResults2['perfDrop'] = paramResults2['test-logloss']/paramResults2['test-logloss'].min()\n",
    "paramResults2.sort_values(['overfit']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>eta</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>bestRound</th>\n",
       "      <th>train-logloss</th>\n",
       "      <th>test-logloss</th>\n",
       "      <th>overfit</th>\n",
       "      <th>perfDrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>978</td>\n",
       "      <td>0.045069</td>\n",
       "      <td>0.086095</td>\n",
       "      <td>91.026728</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>993</td>\n",
       "      <td>0.059650</td>\n",
       "      <td>0.086119</td>\n",
       "      <td>44.373661</td>\n",
       "      <td>1.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>948</td>\n",
       "      <td>0.046388</td>\n",
       "      <td>0.086121</td>\n",
       "      <td>85.655218</td>\n",
       "      <td>1.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>0.054534</td>\n",
       "      <td>0.086127</td>\n",
       "      <td>57.934558</td>\n",
       "      <td>1.000381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>789</td>\n",
       "      <td>0.040434</td>\n",
       "      <td>0.086135</td>\n",
       "      <td>113.026166</td>\n",
       "      <td>1.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>763</td>\n",
       "      <td>0.042060</td>\n",
       "      <td>0.086221</td>\n",
       "      <td>104.998145</td>\n",
       "      <td>1.001473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>993</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.086224</td>\n",
       "      <td>44.633134</td>\n",
       "      <td>1.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>917</td>\n",
       "      <td>0.046019</td>\n",
       "      <td>0.086256</td>\n",
       "      <td>87.434755</td>\n",
       "      <td>1.001870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>0.045286</td>\n",
       "      <td>0.086256</td>\n",
       "      <td>90.468662</td>\n",
       "      <td>1.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>0.048781</td>\n",
       "      <td>0.086265</td>\n",
       "      <td>76.841393</td>\n",
       "      <td>1.001979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>996</td>\n",
       "      <td>0.060807</td>\n",
       "      <td>0.086283</td>\n",
       "      <td>41.896163</td>\n",
       "      <td>1.002186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>998</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.086312</td>\n",
       "      <td>42.024202</td>\n",
       "      <td>1.002523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>997</td>\n",
       "      <td>0.060812</td>\n",
       "      <td>0.086319</td>\n",
       "      <td>41.943366</td>\n",
       "      <td>1.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0.060389</td>\n",
       "      <td>0.086330</td>\n",
       "      <td>42.956025</td>\n",
       "      <td>1.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>874</td>\n",
       "      <td>0.048108</td>\n",
       "      <td>0.086332</td>\n",
       "      <td>79.453900</td>\n",
       "      <td>1.002762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>0.039134</td>\n",
       "      <td>0.086345</td>\n",
       "      <td>120.639958</td>\n",
       "      <td>1.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>686</td>\n",
       "      <td>0.045238</td>\n",
       "      <td>0.086352</td>\n",
       "      <td>90.883811</td>\n",
       "      <td>1.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>797</td>\n",
       "      <td>0.039974</td>\n",
       "      <td>0.086356</td>\n",
       "      <td>116.027257</td>\n",
       "      <td>1.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.059402</td>\n",
       "      <td>0.086359</td>\n",
       "      <td>45.380933</td>\n",
       "      <td>1.003066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>713</td>\n",
       "      <td>0.043326</td>\n",
       "      <td>0.086416</td>\n",
       "      <td>99.456213</td>\n",
       "      <td>1.003733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth   eta  colsample_bytree  gamma  min_child_weight  bestRound  \\\n",
       "42          4  0.01               0.3    0.5                 1        978   \n",
       "12          3  0.01               0.6    0.1                 1        993   \n",
       "36          4  0.01               0.3    0.0                 1        948   \n",
       "24          3  0.10               0.3    0.5                 1        116   \n",
       "75          5  0.01               0.3    0.1                 1        789   \n",
       "78          5  0.01               0.3    0.5                 1        763   \n",
       "9           3  0.01               0.6    0.0                 1        993   \n",
       "45          4  0.01               0.6    0.0                 1        917   \n",
       "33          3  0.10               0.6    0.5                 1        143   \n",
       "39          4  0.01               0.3    0.1                 1        899   \n",
       "6           3  0.01               0.3    0.5                 1        996   \n",
       "3           3  0.01               0.3    0.1                 1        998   \n",
       "0           3  0.01               0.3    0.0                 1        997   \n",
       "18          3  0.10               0.3    0.0                 1         98   \n",
       "51          4  0.01               0.6    0.5                 1        874   \n",
       "57          4  0.10               0.3    0.1                 1        107   \n",
       "81          5  0.01               0.6    0.0                 1        686   \n",
       "72          5  0.01               0.3    0.0                 1        797   \n",
       "15          3  0.01               0.6    0.5                 1        999   \n",
       "84          5  0.01               0.6    0.1                 1        713   \n",
       "\n",
       "    train-logloss  test-logloss     overfit  perfDrop  \n",
       "42       0.045069      0.086095   91.026728  1.000000  \n",
       "12       0.059650      0.086119   44.373661  1.000279  \n",
       "36       0.046388      0.086121   85.655218  1.000307  \n",
       "24       0.054534      0.086127   57.934558  1.000381  \n",
       "75       0.040434      0.086135  113.026166  1.000469  \n",
       "78       0.042060      0.086221  104.998145  1.001473  \n",
       "9        0.059616      0.086224   44.633134  1.001505  \n",
       "45       0.046019      0.086256   87.434755  1.001870  \n",
       "33       0.045286      0.086256   90.468662  1.001879  \n",
       "39       0.048781      0.086265   76.841393  1.001979  \n",
       "6        0.060807      0.086283   41.896163  1.002186  \n",
       "3        0.060773      0.086312   42.024202  1.002523  \n",
       "0        0.060812      0.086319   41.943366  1.002602  \n",
       "18       0.060389      0.086330   42.956025  1.002734  \n",
       "51       0.048108      0.086332   79.453900  1.002762  \n",
       "57       0.039134      0.086345  120.639958  1.002906  \n",
       "81       0.045238      0.086352   90.883811  1.002994  \n",
       "72       0.039974      0.086356  116.027257  1.003032  \n",
       "15       0.059402      0.086359   45.380933  1.003066  \n",
       "84       0.043326      0.086416   99.456213  1.003733  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramResults2.sort_values(['test-logloss']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the max depth 3 will be mnore restrictive, as it will have max of 8 leaves, For var reduction I will prefer model which allows more interactions, so depth of 4,\n",
    "\n",
    "The selected model upto this step is 4,0.01,0.3,0.5,1,978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>eta</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>bestRound</th>\n",
       "      <th>train-logloss</th>\n",
       "      <th>test-logloss</th>\n",
       "      <th>overfit</th>\n",
       "      <th>perfDrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>948</td>\n",
       "      <td>0.046388</td>\n",
       "      <td>0.086121</td>\n",
       "      <td>85.655218</td>\n",
       "      <td>1.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>992</td>\n",
       "      <td>0.065879</td>\n",
       "      <td>0.087265</td>\n",
       "      <td>32.462849</td>\n",
       "      <td>1.013597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>789</td>\n",
       "      <td>0.079599</td>\n",
       "      <td>0.088442</td>\n",
       "      <td>11.109185</td>\n",
       "      <td>1.027263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>0.048781</td>\n",
       "      <td>0.086265</td>\n",
       "      <td>76.841393</td>\n",
       "      <td>1.001979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>38</td>\n",
       "      <td>990</td>\n",
       "      <td>0.065949</td>\n",
       "      <td>0.087196</td>\n",
       "      <td>32.217623</td>\n",
       "      <td>1.012795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>796</td>\n",
       "      <td>0.079510</td>\n",
       "      <td>0.088411</td>\n",
       "      <td>11.194818</td>\n",
       "      <td>1.026905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>978</td>\n",
       "      <td>0.045069</td>\n",
       "      <td>0.086095</td>\n",
       "      <td>91.026728</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>38</td>\n",
       "      <td>752</td>\n",
       "      <td>0.071998</td>\n",
       "      <td>0.087586</td>\n",
       "      <td>21.650601</td>\n",
       "      <td>1.017323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>999</td>\n",
       "      <td>0.077507</td>\n",
       "      <td>0.088307</td>\n",
       "      <td>13.934153</td>\n",
       "      <td>1.025702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0.043562</td>\n",
       "      <td>0.086544</td>\n",
       "      <td>98.669483</td>\n",
       "      <td>1.005224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>0.069966</td>\n",
       "      <td>0.087975</td>\n",
       "      <td>25.739645</td>\n",
       "      <td>1.021841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>108</td>\n",
       "      <td>0.076733</td>\n",
       "      <td>0.088260</td>\n",
       "      <td>15.023341</td>\n",
       "      <td>1.025156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>0.039134</td>\n",
       "      <td>0.086345</td>\n",
       "      <td>120.639958</td>\n",
       "      <td>1.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>38</td>\n",
       "      <td>80</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.087697</td>\n",
       "      <td>24.092485</td>\n",
       "      <td>1.018617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76</td>\n",
       "      <td>172</td>\n",
       "      <td>0.071318</td>\n",
       "      <td>0.088140</td>\n",
       "      <td>23.587033</td>\n",
       "      <td>1.023755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>0.048664</td>\n",
       "      <td>0.086558</td>\n",
       "      <td>77.868330</td>\n",
       "      <td>1.005385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>38</td>\n",
       "      <td>116</td>\n",
       "      <td>0.062035</td>\n",
       "      <td>0.087682</td>\n",
       "      <td>41.343246</td>\n",
       "      <td>1.018438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76</td>\n",
       "      <td>163</td>\n",
       "      <td>0.072028</td>\n",
       "      <td>0.088107</td>\n",
       "      <td>22.324220</td>\n",
       "      <td>1.023377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth   eta  colsample_bytree  gamma  min_child_weight  bestRound  \\\n",
       "36          4  0.01               0.3    0.0                 1        948   \n",
       "37          4  0.01               0.3    0.0                38        992   \n",
       "38          4  0.01               0.3    0.0                76        789   \n",
       "39          4  0.01               0.3    0.1                 1        899   \n",
       "40          4  0.01               0.3    0.1                38        990   \n",
       "41          4  0.01               0.3    0.1                76        796   \n",
       "42          4  0.01               0.3    0.5                 1        978   \n",
       "43          4  0.01               0.3    0.5                38        752   \n",
       "44          4  0.01               0.3    0.5                76        999   \n",
       "54          4  0.10               0.3    0.0                 1         97   \n",
       "55          4  0.10               0.3    0.0                38         83   \n",
       "56          4  0.10               0.3    0.0                76        108   \n",
       "57          4  0.10               0.3    0.1                 1        107   \n",
       "58          4  0.10               0.3    0.1                38         80   \n",
       "59          4  0.10               0.3    0.1                76        172   \n",
       "60          4  0.10               0.3    0.5                 1         86   \n",
       "61          4  0.10               0.3    0.5                38        116   \n",
       "62          4  0.10               0.3    0.5                76        163   \n",
       "\n",
       "    train-logloss  test-logloss     overfit  perfDrop  \n",
       "36       0.046388      0.086121   85.655218  1.000307  \n",
       "37       0.065879      0.087265   32.462849  1.013597  \n",
       "38       0.079599      0.088442   11.109185  1.027263  \n",
       "39       0.048781      0.086265   76.841393  1.001979  \n",
       "40       0.065949      0.087196   32.217623  1.012795  \n",
       "41       0.079510      0.088411   11.194818  1.026905  \n",
       "42       0.045069      0.086095   91.026728  1.000000  \n",
       "43       0.071998      0.087586   21.650601  1.017323  \n",
       "44       0.077507      0.088307   13.934153  1.025702  \n",
       "54       0.043562      0.086544   98.669483  1.005224  \n",
       "55       0.069966      0.087975   25.739645  1.021841  \n",
       "56       0.076733      0.088260   15.023341  1.025156  \n",
       "57       0.039134      0.086345  120.639958  1.002906  \n",
       "58       0.070671      0.087697   24.092485  1.018617  \n",
       "59       0.071318      0.088140   23.587033  1.023755  \n",
       "60       0.048664      0.086558   77.868330  1.005385  \n",
       "61       0.062035      0.087682   41.343246  1.018438  \n",
       "62       0.072028      0.088107   22.324220  1.023377  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramResults2[(paramResults2['max_depth']==4)  & (paramResults2['colsample_bytree']==0.3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable reduction\n",
    "\n",
    "Since we still have 390 features we can aggresively reduce them further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19051, 875)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###  Gget 20% sampel for testing\n",
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "sVars= imp[imp['CummProp'] <= 80]['variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xTrainVars, xTestVars, yTrainVars, yTestVars = train_test_split(xTrain[sVars],\n",
    "                                                                yTrain['cyclooxygenase_inhibitor'], \n",
    "                                                                test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13335, 390), (5716, 390), (13335,), (5716,)\n"
     ]
    }
   ],
   "source": [
    "print(f'{xTrainVars.shape}, {xTestVars.shape}, {yTrainVars.shape}, {yTestVars.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumRows =xTrainVars.shape[0]\n",
    "\n",
    "# 4,0.01,0.3,0.5,1,978\n",
    "params1 = {\n",
    "    'max_depth' : 4,\n",
    "    'eta' : 0.01,\n",
    "    'colsample_bytree' : 0.3,\n",
    "    'min_child_weight' : 1,\n",
    "    'gamma': 0.5,\n",
    "    'objective':'multi:softprob',\n",
    "    'num_class':2\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(xTrainVars, label=yTrainVars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 8s, sys: 52 ms, total: 6min 8s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%time mod1 = xgb.train(params1,dtrain, num_boost_round=978)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.040038868491816794\n",
      "test loss 0.08763258157614282\n"
     ]
    }
   ],
   "source": [
    "print(f'train loss {getLogLoss(yTrainVars,mod1.predict(xgb.DMatrix(xTrainVars))[:,1])}')\n",
    "print(f'test loss {getLogLoss(yTestVars,mod1.predict(xgb.DMatrix(xTestVars))[:,1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08763258157614282"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test loss 0.08763258157614282   Log loss we are starting with\n",
    "\n",
    "testLoss = getLogLoss(yTestVars,mod1.predict(xgb.DMatrix(xTestVars))[:,1])\n",
    "testLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g-228</td>\n",
       "      <td>5.603137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g-319</td>\n",
       "      <td>5.447839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g-38</td>\n",
       "      <td>5.163427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g-714</td>\n",
       "      <td>5.114439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g-40</td>\n",
       "      <td>4.918322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>g-426</td>\n",
       "      <td>1.604592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>g-59</td>\n",
       "      <td>1.542952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>g-415</td>\n",
       "      <td>1.505278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>g-629</td>\n",
       "      <td>1.386211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>g-92</td>\n",
       "      <td>1.308824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    variable      Gain\n",
       "0      g-228  5.603137\n",
       "1      g-319  5.447839\n",
       "2       g-38  5.163427\n",
       "3      g-714  5.114439\n",
       "4       g-40  4.918322\n",
       "..       ...       ...\n",
       "385    g-426  1.604592\n",
       "386     g-59  1.542952\n",
       "387    g-415  1.505278\n",
       "388    g-629  1.386211\n",
       "389     g-92  1.308824\n",
       "\n",
       "[390 rows x 2 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp =pd.DataFrame(mod1.get_score(importance_type='gain').items(),\n",
    "             columns=['variable','Gain']).sort_values(['Gain'],ascending=False).reset_index(drop=True)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "sVars = imp['variable'][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping least important variables \n",
    "def dropVars(sVars,n):\n",
    "    '''\n",
    "    drop variables upto n increasingly from 1 to n\n",
    "    \n",
    "    returns result dropping variables\n",
    "    '''\n",
    "    results ={}\n",
    "    for i in range(1,n):\n",
    "        \n",
    "        remainingVars = sVars[i:] # drop variable\n",
    "        dtrain = xgb.DMatrix(xTrainVars[remainingVars], label=yTrainVars)\n",
    "        mod = xgb.train(params1,dtrain, num_boost_round=978) ## params1 are same selected variables\n",
    "        rLoss = getLogLoss(yTestVars,mod.predict(xgb.DMatrix(xTestVars[remainingVars]))[:,1]) \n",
    "        results[f'dropped_{i}'] = (rLoss,(testLoss-rLoss))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dropVarList = dropVars(sVars,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropped_1': (0.08763258157614282, 0.0),\n",
       " 'dropped_2': (0.08763258157614282, 0.0),\n",
       " 'dropped_3': (0.08763258157614282, 0.0),\n",
       " 'dropped_4': (0.08763258157614282, 0.0),\n",
       " 'dropped_5': (0.08763258157614282, 0.0),\n",
       " 'dropped_6': (0.08763258157614282, 0.0),\n",
       " 'dropped_7': (0.08763258157614282, 0.0),\n",
       " 'dropped_8': (0.08763258157614282, 0.0),\n",
       " 'dropped_9': (0.08763258157614282, 0.0),\n",
       " 'dropped_10': (0.08763258157614282, 0.0),\n",
       " 'dropped_11': (0.08763258157614282, 0.0),\n",
       " 'dropped_12': (0.08763258157614282, 0.0),\n",
       " 'dropped_13': (0.08763258157614282, 0.0),\n",
       " 'dropped_14': (0.08763258157614282, 0.0),\n",
       " 'dropped_15': (0.08763258157614282, 0.0),\n",
       " 'dropped_16': (0.08763258157614282, 0.0),\n",
       " 'dropped_17': (0.08763258157614282, 0.0),\n",
       " 'dropped_18': (0.08763258157614282, 0.0),\n",
       " 'dropped_19': (0.08763258157614282, 0.0),\n",
       " 'dropped_20': (0.08763258157614282, 0.0),\n",
       " 'dropped_21': (0.08763258157614282, 0.0),\n",
       " 'dropped_22': (0.08763258157614282, 0.0),\n",
       " 'dropped_23': (0.08763258157614282, 0.0),\n",
       " 'dropped_24': (0.08763258157614282, 0.0),\n",
       " 'dropped_25': (0.08763258157614282, 0.0),\n",
       " 'dropped_26': (0.08763258157614282, 0.0),\n",
       " 'dropped_27': (0.08763258157614282, 0.0),\n",
       " 'dropped_28': (0.08763258157614282, 0.0),\n",
       " 'dropped_29': (0.08763258157614282, 0.0),\n",
       " 'dropped_30': (0.08763258157614282, 0.0),\n",
       " 'dropped_31': (0.08763258157614282, 0.0),\n",
       " 'dropped_32': (0.08763258157614282, 0.0),\n",
       " 'dropped_33': (0.08763258157614282, 0.0),\n",
       " 'dropped_34': (0.08763258157614282, 0.0),\n",
       " 'dropped_35': (0.08763258157614282, 0.0),\n",
       " 'dropped_36': (0.08763258157614282, 0.0),\n",
       " 'dropped_37': (0.08763258157614282, 0.0),\n",
       " 'dropped_38': (0.08763258157614282, 0.0),\n",
       " 'dropped_39': (0.08763258157614282, 0.0),\n",
       " 'dropped_40': (0.08763258157614282, 0.0),\n",
       " 'dropped_41': (0.08763258157614282, 0.0),\n",
       " 'dropped_42': (0.08763258157614282, 0.0),\n",
       " 'dropped_43': (0.08763258157614282, 0.0),\n",
       " 'dropped_44': (0.08763258157614282, 0.0),\n",
       " 'dropped_45': (0.08763258157614282, 0.0),\n",
       " 'dropped_46': (0.08763258157614282, 0.0),\n",
       " 'dropped_47': (0.08763258157614282, 0.0),\n",
       " 'dropped_48': (0.08763258157614282, 0.0),\n",
       " 'dropped_49': (0.08763258157614282, 0.0),\n",
       " 'dropped_50': (0.08763258157614282, 0.0),\n",
       " 'dropped_51': (0.08763258157614282, 0.0),\n",
       " 'dropped_52': (0.08763258157614282, 0.0),\n",
       " 'dropped_53': (0.08763258157614282, 0.0),\n",
       " 'dropped_54': (0.08763258157614282, 0.0),\n",
       " 'dropped_55': (0.08763258157614282, 0.0),\n",
       " 'dropped_56': (0.08763258157614282, 0.0),\n",
       " 'dropped_57': (0.08763258157614282, 0.0),\n",
       " 'dropped_58': (0.08763258157614282, 0.0),\n",
       " 'dropped_59': (0.08763258157614282, 0.0),\n",
       " 'dropped_60': (0.08763258157614282, 0.0),\n",
       " 'dropped_61': (0.08763258157614282, 0.0),\n",
       " 'dropped_62': (0.08763258157614282, 0.0),\n",
       " 'dropped_63': (0.08763258157614282, 0.0),\n",
       " 'dropped_64': (0.08763258157614282, 0.0),\n",
       " 'dropped_65': (0.08763258157614282, 0.0),\n",
       " 'dropped_66': (0.08763258157614282, 0.0),\n",
       " 'dropped_67': (0.08763258157614282, 0.0),\n",
       " 'dropped_68': (0.08763258157614282, 0.0),\n",
       " 'dropped_69': (0.08763258157614282, 0.0),\n",
       " 'dropped_70': (0.08763258157614282, 0.0),\n",
       " 'dropped_71': (0.08763258157614282, 0.0),\n",
       " 'dropped_72': (0.08763258157614282, 0.0),\n",
       " 'dropped_73': (0.08763258157614282, 0.0),\n",
       " 'dropped_74': (0.08763258157614282, 0.0),\n",
       " 'dropped_75': (0.08763258157614282, 0.0),\n",
       " 'dropped_76': (0.08763258157614282, 0.0),\n",
       " 'dropped_77': (0.08763258157614282, 0.0),\n",
       " 'dropped_78': (0.08763258157614282, 0.0),\n",
       " 'dropped_79': (0.08763258157614282, 0.0),\n",
       " 'dropped_80': (0.08763258157614282, 0.0),\n",
       " 'dropped_81': (0.08763258157614282, 0.0),\n",
       " 'dropped_82': (0.08763258157614282, 0.0),\n",
       " 'dropped_83': (0.08763258157614282, 0.0),\n",
       " 'dropped_84': (0.08763258157614282, 0.0),\n",
       " 'dropped_85': (0.08763258157614282, 0.0),\n",
       " 'dropped_86': (0.08763258157614282, 0.0),\n",
       " 'dropped_87': (0.08763258157614282, 0.0),\n",
       " 'dropped_88': (0.08763258157614282, 0.0),\n",
       " 'dropped_89': (0.08763258157614282, 0.0),\n",
       " 'dropped_90': (0.08763258157614282, 0.0),\n",
       " 'dropped_91': (0.08763258157614282, 0.0),\n",
       " 'dropped_92': (0.08763258157614282, 0.0),\n",
       " 'dropped_93': (0.08763258157614282, 0.0),\n",
       " 'dropped_94': (0.08763258157614282, 0.0),\n",
       " 'dropped_95': (0.08763258157614282, 0.0),\n",
       " 'dropped_96': (0.08763258157614282, 0.0),\n",
       " 'dropped_97': (0.08763258157614282, 0.0),\n",
       " 'dropped_98': (0.08763258157614282, 0.0),\n",
       " 'dropped_99': (0.08763258157614282, 0.0),\n",
       " 'dropped_100': (0.08763258157614282, 0.0),\n",
       " 'dropped_101': (0.08763258157614282, 0.0),\n",
       " 'dropped_102': (0.08763258157614282, 0.0),\n",
       " 'dropped_103': (0.08763258157614282, 0.0),\n",
       " 'dropped_104': (0.08763258157614282, 0.0),\n",
       " 'dropped_105': (0.08763258157614282, 0.0),\n",
       " 'dropped_106': (0.08763258157614282, 0.0),\n",
       " 'dropped_107': (0.08763258157614282, 0.0),\n",
       " 'dropped_108': (0.08763258157614282, 0.0),\n",
       " 'dropped_109': (0.08763258157614282, 0.0),\n",
       " 'dropped_110': (0.08763258157614282, 0.0),\n",
       " 'dropped_111': (0.08763258157614282, 0.0),\n",
       " 'dropped_112': (0.08763258157614282, 0.0),\n",
       " 'dropped_113': (0.08763258157614282, 0.0),\n",
       " 'dropped_114': (0.08763258157614282, 0.0),\n",
       " 'dropped_115': (0.08763258157614282, 0.0),\n",
       " 'dropped_116': (0.08763258157614282, 0.0),\n",
       " 'dropped_117': (0.08763258157614282, 0.0),\n",
       " 'dropped_118': (0.08763258157614282, 0.0),\n",
       " 'dropped_119': (0.08763258157614282, 0.0),\n",
       " 'dropped_120': (0.08763258157614282, 0.0),\n",
       " 'dropped_121': (0.08763258157614282, 0.0),\n",
       " 'dropped_122': (0.08763258157614282, 0.0),\n",
       " 'dropped_123': (0.08763258157614282, 0.0),\n",
       " 'dropped_124': (0.08763258157614282, 0.0),\n",
       " 'dropped_125': (0.08763258157614282, 0.0),\n",
       " 'dropped_126': (0.08763258157614282, 0.0),\n",
       " 'dropped_127': (0.08763258157614282, 0.0),\n",
       " 'dropped_128': (0.08763258157614282, 0.0),\n",
       " 'dropped_129': (0.08763258157614282, 0.0),\n",
       " 'dropped_130': (0.08763258157614282, 0.0),\n",
       " 'dropped_131': (0.08763258157614282, 0.0),\n",
       " 'dropped_132': (0.08763258157614282, 0.0),\n",
       " 'dropped_133': (0.08763258157614282, 0.0),\n",
       " 'dropped_134': (0.08763258157614282, 0.0),\n",
       " 'dropped_135': (0.08763258157614282, 0.0),\n",
       " 'dropped_136': (0.08763258157614282, 0.0),\n",
       " 'dropped_137': (0.08763258157614282, 0.0),\n",
       " 'dropped_138': (0.08763258157614282, 0.0),\n",
       " 'dropped_139': (0.08763258157614282, 0.0),\n",
       " 'dropped_140': (0.08763258157614282, 0.0),\n",
       " 'dropped_141': (0.08763258157614282, 0.0),\n",
       " 'dropped_142': (0.08763258157614282, 0.0),\n",
       " 'dropped_143': (0.08763258157614282, 0.0),\n",
       " 'dropped_144': (0.08763258157614282, 0.0),\n",
       " 'dropped_145': (0.08763258157614282, 0.0),\n",
       " 'dropped_146': (0.08763258157614282, 0.0),\n",
       " 'dropped_147': (0.08763258157614282, 0.0),\n",
       " 'dropped_148': (0.08763258157614282, 0.0),\n",
       " 'dropped_149': (0.08763258157614282, 0.0),\n",
       " 'dropped_150': (0.08763258157614282, 0.0),\n",
       " 'dropped_151': (0.08763258157614282, 0.0),\n",
       " 'dropped_152': (0.08763258157614282, 0.0),\n",
       " 'dropped_153': (0.08763258157614282, 0.0),\n",
       " 'dropped_154': (0.08763258157614282, 0.0),\n",
       " 'dropped_155': (0.08763258157614282, 0.0),\n",
       " 'dropped_156': (0.08763258157614282, 0.0),\n",
       " 'dropped_157': (0.08763258157614282, 0.0),\n",
       " 'dropped_158': (0.08763258157614282, 0.0),\n",
       " 'dropped_159': (0.08763258157614282, 0.0),\n",
       " 'dropped_160': (0.08763258157614282, 0.0),\n",
       " 'dropped_161': (0.08763258157614282, 0.0),\n",
       " 'dropped_162': (0.08763258157614282, 0.0),\n",
       " 'dropped_163': (0.08763258157614282, 0.0),\n",
       " 'dropped_164': (0.08763258157614282, 0.0),\n",
       " 'dropped_165': (0.08763258157614282, 0.0),\n",
       " 'dropped_166': (0.08763258157614282, 0.0),\n",
       " 'dropped_167': (0.08763258157614282, 0.0),\n",
       " 'dropped_168': (0.08763258157614282, 0.0),\n",
       " 'dropped_169': (0.08763258157614282, 0.0),\n",
       " 'dropped_170': (0.08763258157614282, 0.0),\n",
       " 'dropped_171': (0.08763258157614282, 0.0),\n",
       " 'dropped_172': (0.08763258157614282, 0.0),\n",
       " 'dropped_173': (0.08763258157614282, 0.0),\n",
       " 'dropped_174': (0.08763258157614282, 0.0),\n",
       " 'dropped_175': (0.08763258157614282, 0.0),\n",
       " 'dropped_176': (0.08763258157614282, 0.0),\n",
       " 'dropped_177': (0.08763258157614282, 0.0),\n",
       " 'dropped_178': (0.08763258157614282, 0.0),\n",
       " 'dropped_179': (0.08763258157614282, 0.0),\n",
       " 'dropped_180': (0.08763258157614282, 0.0),\n",
       " 'dropped_181': (0.08763258157614282, 0.0),\n",
       " 'dropped_182': (0.08763258157614282, 0.0),\n",
       " 'dropped_183': (0.08763258157614282, 0.0),\n",
       " 'dropped_184': (0.08763258157614282, 0.0),\n",
       " 'dropped_185': (0.08763258157614282, 0.0),\n",
       " 'dropped_186': (0.08763258157614282, 0.0),\n",
       " 'dropped_187': (0.08763258157614282, 0.0),\n",
       " 'dropped_188': (0.08763258157614282, 0.0),\n",
       " 'dropped_189': (0.08763258157614282, 0.0),\n",
       " 'dropped_190': (0.08763258157614282, 0.0),\n",
       " 'dropped_191': (0.08763258157614282, 0.0),\n",
       " 'dropped_192': (0.08763258157614282, 0.0),\n",
       " 'dropped_193': (0.08763258157614282, 0.0),\n",
       " 'dropped_194': (0.08763258157614282, 0.0),\n",
       " 'dropped_195': (0.08763258157614282, 0.0),\n",
       " 'dropped_196': (0.08763258157614282, 0.0),\n",
       " 'dropped_197': (0.08763258157614282, 0.0),\n",
       " 'dropped_198': (0.08763258157614282, 0.0),\n",
       " 'dropped_199': (0.08763258157614282, 0.0)}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropVarList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
